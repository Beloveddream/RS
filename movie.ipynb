{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOc+Fsxuvbzk6vu1EPbKMN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beloveddream/RS/blob/main/movie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsXSceFxyhGj",
        "outputId": "20e8cb2b-2142-4d62-f251-3925d639ad3e"
      },
      "source": [
        "!pip install deepctr"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepctr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/2c/dd9dd105e366d80328fbbf1312d2623d41c8bfbd56ed14390b6c59d6719b/deepctr-0.8.6-py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepctr) (2.23.0)\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deepctr) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deepctr) (1.19.5)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h5py, deepctr\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed deepctr-0.8.6 h5py-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRSeex1qSWso",
        "outputId": "ad8536c9-fb96-4f8b-825f-407737e25996"
      },
      "source": [
        "pip install surprise"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 224kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617622 sha256=588523ecae72386815e4872d26638f9427e561388c8ed16ec6fe97eb3e9a2e09\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1YVyIqrzuJG",
        "outputId": "d95e21ad-4508-48c0-f377-23e4cb522377"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrS1ZtjKyV6q"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from deepctr.models import DeepFM\n",
        "#from deepctr.inputs import SparseFeat,get_feature_names\n",
        "from deepctr.feature_column import SparseFeat,get_feature_names"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgYOuzmRQ9Kr"
      },
      "source": [
        "**DeepFM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oriqrkzmzkQ_",
        "outputId": "5987425a-2c4b-4931-b46a-238e91cc219f"
      },
      "source": [
        "#数据加载\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/movielens/movielens_sample.txt\")\n",
        "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "target = ['rating']\n",
        "\n",
        "# 对特征标签进行编码\n",
        "for feature in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feature] = lbe.fit_transform(data[feature])\n",
        "# 计算每个特征中的 不同特征值的个数\n",
        "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
        "print(fixlen_feature_columns)\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 将数据集切分成训练集和测试集\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train_model_input = {name:train[name].values for name in feature_names}\n",
        "test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "# 使用DeepFM进行训练\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
        "# 使用DeepFM进行预测\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "# 输出RMSE或MSE\n",
        "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
        "rmse = mse ** 0.5\n",
        "print(\"test RMSE\", rmse)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[SparseFeat(name='movie_id', vocabulary_size=187, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a5107c090>, embedding_name='movie_id', group_name='default_group', trainable=True), SparseFeat(name='user_id', vocabulary_size=193, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a5053e2d0>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='gender', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a50541e50>, embedding_name='gender', group_name='default_group', trainable=True), SparseFeat(name='age', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a525c95d0>, embedding_name='age', group_name='default_group', trainable=True), SparseFeat(name='occupation', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a543b5210>, embedding_name='occupation', group_name='default_group', trainable=True), SparseFeat(name='zip', vocabulary_size=188, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f1a5107ac10>, embedding_name='zip', group_name='default_group', trainable=True)]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 13.7813 - mse: 13.7813 - val_loss: 14.9509 - val_mse: 14.9509\n",
            "test RMSE 3.800052631214468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-puD3y9WQ63"
      },
      "source": [
        "**Wide_Deep** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wnuV7kWQNv"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr.models import WDL\n",
        "#from deepctr.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr.feature_column import SparseFeat,get_feature_names,DenseFeat"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlMY7XkOWpg4",
        "outputId": "8daeef09-1dcb-473b-a3eb-75c528c33d0d"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/My Drive/movielens/movielens_sample.txt')\n",
        "sparse_features = ['user_id', 'movie_id', 'timestamp', 'title', 'genres', 'gender', 'occupation', 'zip']\n",
        "dense_features = ['age']\n",
        "target = ['rating']\n",
        "\n",
        "# 对特征标签进行编码\n",
        "for feature in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feature] = lbe.fit_transform(data[feature])\n",
        "\n",
        "mms = MinMaxScaler(feature_range=(0,1))\n",
        "data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "# 计算每个特征中的 不同特征值的个数\n",
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique())\n",
        "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1)\n",
        "                      for feat in dense_features]\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 将数据集切分成训练集和测试集\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train_model_input = {name:train[name].values for name in feature_names}\n",
        "test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "# 使用WDL进行训练\n",
        "model = WDL(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'] )\n",
        "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=True, validation_split=0.2 )\n",
        "# 使用WDL进行预测\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "# 输出RMSE或MSE\n",
        "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
        "rmse = mse ** 0.5\n",
        "print(\"test RMSE\", rmse)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 15.0138 - mse: 15.0138 - val_loss: 15.6914 - val_mse: 15.6913\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 14.6977 - mse: 14.6977 - val_loss: 15.4098 - val_mse: 15.4098\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 14.3825 - mse: 14.3825 - val_loss: 15.1310 - val_mse: 15.1310\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 14.0714 - mse: 14.0714 - val_loss: 14.8550 - val_mse: 14.8550\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.7645 - mse: 13.7645 - val_loss: 14.5798 - val_mse: 14.5798\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.4575 - mse: 13.4574 - val_loss: 14.3024 - val_mse: 14.3024\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13.1481 - mse: 13.1481 - val_loss: 14.0174 - val_mse: 14.0174\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.8299 - mse: 12.8299 - val_loss: 13.7192 - val_mse: 13.7192\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.4982 - mse: 12.4982 - val_loss: 13.4081 - val_mse: 13.4081\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.1537 - mse: 12.1537 - val_loss: 13.0858 - val_mse: 13.0858\n",
            "test RMSE 3.496412447066278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCIktwVXmVf"
      },
      "source": [
        "**SVD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOaDNs8FkD1"
      },
      "source": [
        "from surprise import SVD , SVDpp\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import os"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIXTpSgGSpKp"
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/les2\")\n",
        "time1=time.time()\n",
        "\n",
        "# 数据读取\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "data = Dataset.load_from_file('ratings.csv', reader=reader)\n",
        "train_set = data.build_full_trainset()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTta0UhGTEPQ",
        "outputId": "ce68c01b-7cfc-47f2-e7da-9334624865eb"
      },
      "source": [
        "# 使用funkSVD\n",
        "algo_1 = SVD(biased=False)\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf_1 = KFold(n_splits=3)\n",
        "print(\"使用funkSVD模型：\")\n",
        "for trainset, testset in kf_1.split(data):\n",
        "    # 训练并预测\n",
        "    algo_1.fit(trainset)\n",
        "    predictions = algo_1.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用funkSVD模型：\n",
            "RMSE: 0.8758\n",
            "RMSE: 0.8726\n",
            "RMSE: 0.8723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "odbb1Il3TH0p",
        "outputId": "ca7db4a6-0b71-4c3c-eca9-ca45e81885ed"
      },
      "source": [
        "# 使用BiasSVD\n",
        "algo_2 = SVD(biased=True)\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf_2 = KFold(n_splits=3)\n",
        "print(\"使用BiasSVD模型：\")\n",
        "for trainset, testset in kf_2.split(data):\n",
        "    # 训练并预测\n",
        "    algo_2.fit(trainset)\n",
        "    predictions = algo_2.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "\n",
        "# 使用SVD++\n",
        "algo_3 = SVDpp()\n",
        "\n",
        "# 定义K折交叉验证迭代器，K=3\n",
        "kf_3 = KFold(n_splits=3)\n",
        "print(\"使用SVD++模型：\")\n",
        "for trainset, testset in kf_3.split(data):\n",
        "    # 训练并预测\n",
        "    algo_3.fit(trainset)\n",
        "    predictions = algo_3.test(testset)\n",
        "    # 计算RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "\n",
        "time2=time.time()\n",
        "print(time2-time1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用BiasSVD模型：\n",
            "RMSE: 0.8431\n",
            "RMSE: 0.8466\n",
            "RMSE: 0.8449\n",
            "使用SVD++模型：\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3d94aed3193a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 训练并预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0malgo_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 计算RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.sgd\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/trainset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}